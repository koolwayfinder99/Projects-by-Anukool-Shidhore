# Multi-Modal Sensor Fusion (LiDAR & Radar) for Mobile Robotics

**Role:** Perception Engineer
**Duration:** Mar 2025 - Aug 2025
**Tech Stack:** ROS 2, Kalman Filters, LiDAR, Radar, C++/Python

## Project Overview
Developed a robust perception framework by fusing LiDAR point clouds and Radar data to generate dense 3D spatial maps for environmental understanding.

## Key Technical Contributions
* **Sensor Fusion:** Implemented **Kalman Filtering** techniques to integrate sensor streams from LiDAR (spatial accuracy) and Radar (velocity estimation/robustness).
* **SLAM:** Enabled Simultaneous Localization and Mapping (SLAM) and precise object tracking in unstructured environments.
* **Path Planning:** Facilitated accurate obstacle detection, velocity estimation, and dynamic path planning based on the fused sensor output.